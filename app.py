import streamlit as st
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# 1. Web config 
st.set_page_config(page_title="Student Feedback AI", page_icon="ğŸ“")

st.title("ğŸ“ PhÃ¢n loáº¡i Feedback Sinh ViÃªn")
st.write("Nháº­p pháº£n há»“i cá»§a sinh viÃªn Ä‘á»ƒ AI phÃ¢n loáº¡i cáº£m xÃºc.")

# 2. Load Model
@st.cache_resource
def load_ai_model():
    model_path = "bachng23/PhoBERT_FineTuned_Student_Feedback"
    
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)
        return tokenizer, model
    except Exception as e:
        st.error(f"Lá»—i khÃ´ng tÃ¬m tháº¥y Model: {e}")
        return None, None

# Load model
with st.spinner("Äang khá»Ÿi Ä‘á»™ng 'bá»™ nÃ£o' AI..."):
    tokenizer, model = load_ai_model()

# 3. UI
text_input = st.text_area("Ná»™i dung Feedback:", height=100, placeholder="VÃ­ dá»¥: Tháº§y dáº¡y hay nhÆ°ng bÃ i táº­p khÃ³ quÃ¡...")

btn_predict = st.button("ğŸ” PhÃ¢n tÃ­ch ngay")

# 4. Button Function
if btn_predict:
    if not text_input.strip():
        st.warning("Báº¡n chÆ°a nháº­p ná»™i dung nÃ o cáº£!")
    else:
        if tokenizer is None or model is None:
            st.error("Model chÆ°a Ä‘Æ°á»£c load thÃ nh cÃ´ng. Kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n folder.")
        else:
            # --- Start Predicting ---
            inputs = tokenizer(text_input, return_tensors="pt", truncation=True, max_length=256)
            
            with torch.no_grad():
                outputs = model(**inputs)
            
            # Calculate Prob (Softmax)
            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
            probs_list = probs[0].tolist()
            
            # Take the highest prob index
            pred_idx = torch.argmax(probs).item()
            
            # Mapping
            labels_map = {0: "TiÃªu cá»±c ğŸ˜¡", 1: "Trung tÃ­nh ğŸ˜", 2: "TÃ­ch cá»±c ğŸ˜„"}
            colors_map = {0: "red", 1: "orange", 2: "green"}
            
            result_text = labels_map[pred_idx]
            confidence = probs_list[pred_idx]

            # --- Show Result ---
            st.markdown("---")
            st.subheader(f"Káº¿t quáº£: :{colors_map[pred_idx]}[{result_text}]")
            st.caption(f"Äá»™ tin cáº­y: {confidence:.2%}")
            st.write("Chi tiáº¿t Ä‘iá»ƒm sá»‘:")
            col1, col2, col3 = st.columns(3)
            col1.metric("TiÃªu cá»±c", f"{probs_list[0]:.2%}")
            col2.metric("Trung tÃ­nh", f"{probs_list[1]:.2%}")
            col3.metric("TÃ­ch cá»±c", f"{probs_list[2]:.2%}")